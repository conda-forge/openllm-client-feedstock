{% set name = "openllm-client" %}
{% set version = "0.5.7" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/openllm_client-{{ version }}.tar.gz
  sha256: 5fa9ab4b5d65a149dce91328bf734123846b8e48af3cdc16ee183e809db61b00

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 1

requirements:
  host:
    - python {{ python_min }}
    - hatchling ==1.18.0
    - hatch-vcs ==0.3.0
    - hatch-fancy-pypi-readme ==23.1.0
    - pip
  run:
    - python >={{ python_min }}
    - openllm-core
    - httpx
    - distro
    - anyio

test:
  imports:
    - openllm_client
  commands:
    - pip check
  requires:
    - pip
    - python {{ python_min }}

about:
  summary: 'OpenLLM Client: Interacting with OpenLLM HTTP/gRPC server, or any BentoML server.'
  home: https://github.com/bentoml/OpenLLM
  license: Apache-2.0
  license_file: LICENSE.md

extra:
  recipe-maintainers:
    - rxm7706
    - conda-forge/openllm-core
